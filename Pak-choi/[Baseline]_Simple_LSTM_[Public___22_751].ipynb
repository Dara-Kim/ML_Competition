{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. 데이터 전처리>>baseline에 있는대로 사용해도 괜찮은가? 누락된 값이 있는 데이터를 그냥 0으로 바꿔서 처리하는 것이 맞는가?\n",
        "2. 모델의 layer, optimizer, gradient도 다시 확인\n",
        "3. 추가적인 외부데이터를 사용할 때 어떤 데이터를 찾아야하는가?\n",
        "4. CFG값을 어떻게 바꿀 것인가?\n",
        "5. K-NN?K-MEANS?"
      ],
      "metadata": {
        "id": "D_nQoYeHEa6V"
      },
      "id": "D_nQoYeHEa6V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* csv 파일 보면 (x,38)짜리이고, x(데이터 개수)는 파일마다 다름\n",
        "* 시간 열을 사용하여 데이터를 맞춰주고 시간도 일단위로 통일\n",
        "input data의  경우 시간과 그 외 37개에 대한 데이터가 있고, target data의 경우 시간과 잎면적 증감률에 대한 데이터가 있음\n",
        "이때 input data의 경우 시간이 분단위, target의 경우 일별\n",
        "* 시간을 제외하고 37개의 요인을 통해 예측하므로 input_size=37, output은 1"
      ],
      "metadata": {
        "id": "ICPxNBnwYiU3"
      },
      "id": "ICPxNBnwYiU3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#여기서 부터 새로운것!!!"
      ],
      "metadata": {
        "id": "mShceIIHnCpq"
      },
      "id": "mShceIIHnCpq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 시간이 중복되는 데이터 있으나 결과값이 다름>>다른 개체\n",
        "* 시간 누락값 없음.\n",
        ">>각 데이터파일마다 데이터 개수는 달라도 누락값은 없음\n",
        "input data의 시간과 target data의 시간이 하루 차이가 남>>결과가 다음날의 잎면적 증감률에 관한 것이므로 데이터가 다 있음\n",
        "* case43만 데이터 시작 시간이 다름. 나머지는 00:00:00이지만 얘는 21일\n",
        "10:53:00부터 시작, target 데이터도 23일부터 시작.\n",
        ">>21일에 해당하는 데이터는 그냥 버려져야 하는데 마지막 부분이 버려짐(기존 베이스라인 코드에서 앞에서부터 1440씩 단위로 끊어서)"
      ],
      "metadata": {
        "id": "NoR_4AWJlqMc"
      },
      "id": "NoR_4AWJlqMc"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "-HBElQ_s60c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6092f8a0-e98c-40f7-bb02-fa4e86ea795d"
      },
      "id": "-HBElQ_s60c3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /gdrive/My\\ Drive/데이콘\n",
        "!ls"
      ],
      "metadata": {
        "id": "uOMnJMvF61ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cec57f4-8d8f-4db9-cdd9-3a49db79de62"
      },
      "id": "uOMnJMvF61ln",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/데이콘\n",
            "'[Baseline]_Simple LSTM [Public _ 22.751].ipynb'   test_input\t train_target\n",
            " sample_submission.zip\t\t\t\t   test_target\n",
            " submission.zip\t\t\t\t\t   train_input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c8398e6f-c83e-4190-9fec-d259e78578f7",
      "metadata": {
        "id": "c8398e6f-c83e-4190-9fec-d259e78578f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee7f281-98ac-487c-e071-0c46e81d5da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  9 03:17:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
      "metadata": {
        "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
      "metadata": {
        "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
      "metadata": {
        "id": "d13862e3-bb27-47af-9b58-a9fbf804df71"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
      "metadata": {
        "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
      },
      "source": [
        "## Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
      "metadata": {
        "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'EPOCHS':5,#같은 데이터셋을 얼마나 반복 학습할 것인가\n",
        "    'LEARNING_RATE':1e-3,#gradient 보폭\n",
        "    'BATCH_SIZE':16,#가중치값 업데이트 주기\n",
        "    'SEED':41\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
      "metadata": {
        "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
      },
      "source": [
        "## Fixed RandomSeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
      "metadata": {
        "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
      "metadata": {
        "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
      },
      "source": [
        "## Data Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
      "metadata": {
        "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d"
      },
      "outputs": [],
      "source": [
        "all_input_list = sorted(glob.glob('./train_input/*.csv'))\n",
        "all_target_list = sorted(glob.glob('./train_target/*.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 경로 리스트 만들어준 것"
      ],
      "metadata": {
        "id": "V8pCdB2JwZU2"
      },
      "id": "V8pCdB2JwZU2"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a99a2ef1-ba9d-45b1-9581-0bcc82e96b69",
      "metadata": {
        "id": "a99a2ef1-ba9d-45b1-9581-0bcc82e96b69"
      },
      "outputs": [],
      "source": [
        "train_input_list = all_input_list[:50]\n",
        "train_target_list = all_target_list[:50]\n",
        "\n",
        "val_input_list = all_input_list[50:]\n",
        "val_target_list = all_target_list[50:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###csv 파일 보면 (x,38)짜리이고, x(데이터 개수)는 파일마다 다름"
      ],
      "metadata": {
        "id": "rJFAnks7_dVT"
      },
      "id": "rJFAnks7_dVT"
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "for i in range(len(train_input_list)):\n",
        "  test_df=pd.read_csv(train_input_list[i])\n",
        "  time=test_df['시간']\n",
        "  first=time.iloc[0]\n",
        "  last=time.iloc[len(time)-1]\n",
        "  dataformat=\"%Y-%m-%d %H:%M:%S\"\n",
        "  datetime_first=datetime.datetime.strptime(first, dataformat)\n",
        "  datetime_last=datetime.datetime.strptime(last, dataformat)\n",
        "  res=datetime_last-datetime_first\n",
        "  if len(time)-1==res.days*24*60+res.seconds/60:\n",
        "  #if len(time)-1==res.days://target data의 경우\n",
        "    print(\"True\")\n",
        "  elif len(time)-1>res.days*24*60+res.seconds/60:\n",
        "  #elif len(time)-1>res.days:  \n",
        "    print(\"데이터 누락\")\n",
        "  else:\n",
        "    print(\"데이터 오류\")\n"
      ],
      "metadata": {
        "id": "3VQPgf-LHMqy"
      },
      "id": "3VQPgf-LHMqy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "for i in range(len(train_target_list)):\n",
        "  test_df=pd.read_csv(train_target_list[i])\n",
        "  time=test_df['시간']\n",
        "  first=time.iloc[0]\n",
        "  last=time.iloc[len(time)-1]\n",
        "  dataformat=\"%Y-%m-%d %H:%M:%S\"\n",
        "  datetime_first=datetime.datetime.strptime(first, dataformat)\n",
        "  datetime_last=datetime.datetime.strptime(last, dataformat)\n",
        "  res=datetime_last-datetime_first\n",
        "  if len(time)-1==res.days:\n",
        "    print(\"True\")\n",
        "  elif len(time)-1>res.days:  \n",
        "    print(\"데이터 누락\")\n",
        "  else:\n",
        "    print(\"데이터 오류\")"
      ],
      "metadata": {
        "id": "ESmkyY-oQs7w"
      },
      "id": "ESmkyY-oQs7w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시작날짜/마지막 날짜 일치하는지 확인\n",
        "for input_path, target_path in tqdm(zip(train_input_list, train_target_list)):\n",
        "    input_df = pd.read_csv(input_path)\n",
        "    target_df = pd.read_csv(target_path)\n",
        "    dataformat=\"%Y-%m-%d %H:%M:%S\"\n",
        "    time=input_df['시간']\n",
        "    time2=target_df['시간']\n",
        "    first_input=time.iloc[0]\n",
        "    first_target=time2.iloc[0]\n",
        "    input_time_first=datetime.datetime.strptime(first_input, dataformat)\n",
        "    target_time_first=datetime.datetime.strptime(first_target, dataformat)\n",
        "    print(input_time_first)\n",
        "    print(target_time_first)"
      ],
      "metadata": {
        "id": "AqeWFwh8RMHc"
      },
      "id": "AqeWFwh8RMHc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
      "metadata": {
        "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e"
      },
      "source": [
        "## CustomDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시간 열을 사용하여 데이터를 맞춰주고 시간도 일단위로 통일\n",
        "###input data의  경우 시간과 그 외 37개에 대한 데이터가 있고, target data의 경우 시간과 잎면적 증감률에 대한 데이터가 있음. 이때 input data의 경우 시간이 분단위, target의 경우 일별"
      ],
      "metadata": {
        "id": "yciI3Hx9HMxi"
      },
      "id": "yciI3Hx9HMxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
      "metadata": {
        "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_paths, target_paths, infer_mode):\n",
        "        self.input_paths = input_paths\n",
        "        self.target_paths = target_paths\n",
        "        self.infer_mode = infer_mode\n",
        "        \n",
        "        self.data_list = []\n",
        "        self.label_list = []\n",
        "        print('Data Pre-processing..')\n",
        "        #학습데이터셋 읽어오기\n",
        "        for input_path, target_path in tqdm(zip(self.input_paths, self.target_paths)):\n",
        "            input_df = pd.read_csv(input_path)\n",
        "            target_df = pd.read_csv(target_path)\n",
        "            #파일 중 '시간'열에 해당하는 부분 삭제\n",
        "            input_df = input_df.drop(columns=['시간'])\n",
        "            #빈 부분 0으로 채우기\n",
        "            input_df = input_df.fillna(0)\n",
        "            #cvs 파일에서 input은 시간이 분단위, target은 하루단위>>하루 단위로 단위 통일\n",
        "            input_length = int(len(input_df)/1440)\n",
        "            target_length = int(len(target_df))\n",
        "            for idx in range(target_length):\n",
        "                time_series = input_df[1440*idx:1440*(idx+1)].values\n",
        "                self.data_list.append(torch.Tensor(time_series))\n",
        "            for label in target_df[\"rate\"]:\n",
        "                self.label_list.append(label)\n",
        "        print('Done.')\n",
        "              \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data_list[index]\n",
        "        label = self.label_list[index]\n",
        "        if self.infer_mode == False:\n",
        "            return data, label\n",
        "        else:\n",
        "            return data\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d880481-1965-499d-9caa-fdfa8526f789",
      "metadata": {
        "id": "9d880481-1965-499d-9caa-fdfa8526f789"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_input_list, train_target_list, False)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=6)#num_workers는 cpu 코어 몇개 쓸지\n",
        "\n",
        "val_dataset = CustomDataset(val_input_list, val_target_list, False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(train_dataset.__len__())\n",
        "print(type(train_dataset))\n",
        "#print(train_dataset.__getitem__(0).size)\n",
        "display(train_dataset.__getitem__(0))\n",
        "print(len(val_dataset))\n",
        "\n",
        "print(type(val_dataset))"
      ],
      "metadata": {
        "id": "FepHRYsAsA1H"
      },
      "id": "FepHRYsAsA1H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(val_dataset.data_list)\n",
        "print(type(val_dataset.data_list))\n",
        "\n",
        "data_list=np.asarray(val_dataset.data_list)\n",
        "print(data_list.shape)"
      ],
      "metadata": {
        "id": "t92vUBMfhvOS"
      },
      "id": "t92vUBMfhvOS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "39962463-032f-490a-a76d-c03991795f38",
      "metadata": {
        "id": "39962463-032f-490a-a76d-c03991795f38"
      },
      "source": [
        "## Model Define"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###시간을 제외하고 37개의 요인을 통해 예측하므로 input_size=37, output은 1"
      ],
      "metadata": {
        "id": "kiMChpm7IERc"
      },
      "id": "kiMChpm7IERc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
      "metadata": {
        "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "        #input은 그냥 입력값(시간을 제외한 37개의 요인을 활용하기 때문), hidden은 셀 갯수, batch_first=True는 output이 (batch, seq,feature)라는 뜻, bidrectional=false는 단방향 rnn\n",
        "        self.lstm = nn.LSTM(input_size=37, hidden_size=256, batch_first=True, bidirectional=False)\n",
        "        #input 256개에 결과는 하나(아무래도 뭐 청경채 결과는 rate 하나니까...)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        hidden, _ = self.lstm(x)\n",
        "        output = self.classifier(hidden[:,-1,:])\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
      "metadata": {
        "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
      "metadata": {
        "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    #gpu에서 연산하려고 tensor 가져오는 것\n",
        "    model.to(device)\n",
        "    #MAE로 LOSS 계산한다\n",
        "    criterion = nn.L1Loss().to(device)\n",
        "    \n",
        "    best_loss = 9999\n",
        "    best_model = None\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for X, Y in tqdm(iter(train_loader)):\n",
        "            X = X.to(device)\n",
        "            Y = Y.to(device)\n",
        "            #학습이 원하는 방향으로 이루어 지도록 gradient를 0으로 초기화\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(X)\n",
        "            loss = criterion(output, Y)\n",
        "            #loss값은 원래 거꾸로 계산하는거...\n",
        "            loss.backward()\n",
        "            #.step()은 업데이트 메소드\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss.append(loss.item())\n",
        "                    \n",
        "        val_loss = validation(model, val_loader, criterion, device)\n",
        "        \n",
        "        print(f'Train Loss : [{np.mean(train_loss):.5f}] Valid Loss : [{val_loss:.5f}]')\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "            \n",
        "        if best_loss > val_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model = model\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24d422f-6e6d-4659-a6f8-c17e7f6761ba",
      "metadata": {
        "id": "a24d422f-6e6d-4659-a6f8-c17e7f6761ba"
      },
      "outputs": [],
      "source": [
        "def validation(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    with torch.no_grad():\n",
        "        for X, Y in tqdm(iter(val_loader)):\n",
        "            X = X.float().to(device)\n",
        "            Y = Y.float().to(device)\n",
        "            \n",
        "            model_pred = model(X)\n",
        "            loss = criterion(model_pred, Y)\n",
        "            \n",
        "            val_loss.append(loss.item())\n",
        "            \n",
        "    return np.mean(val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
      "metadata": {
        "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
      },
      "source": [
        "## Run!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86142d9a-68b7-4d04-8423-49d28025411d",
      "metadata": {
        "tags": [],
        "id": "86142d9a-68b7-4d04-8423-49d28025411d"
      },
      "outputs": [],
      "source": [
        "model = BaseModel()\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "scheduler = None\n",
        "\n",
        "best_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93c88c8-95f2-4eae-a9ff-c81becba0d97",
      "metadata": {
        "id": "a93c88c8-95f2-4eae-a9ff-c81becba0d97"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46d7d60-38d7-44d6-82f2-836738b5a85e",
      "metadata": {
        "id": "f46d7d60-38d7-44d6-82f2-836738b5a85e"
      },
      "outputs": [],
      "source": [
        "test_input_list = sorted(glob.glob('./test_input/*.csv'))\n",
        "test_target_list = sorted(glob.glob('./test_target/*.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1defba-fdc0-4fe4-8c59-36d338851f15",
      "metadata": {
        "id": "ad1defba-fdc0-4fe4-8c59-36d338851f15"
      },
      "outputs": [],
      "source": [
        "def inference_per_case(model, test_loader, test_path, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for X in iter(test_loader):\n",
        "            X = X.float().to(device)\n",
        "            \n",
        "            model_pred = model(X)\n",
        "            \n",
        "            model_pred = model_pred.cpu().numpy().reshape(-1).tolist()\n",
        "            \n",
        "            pred_list += model_pred\n",
        "    \n",
        "    submit_df = pd.read_csv(test_path)\n",
        "    submit_df['rate'] = pred_list\n",
        "    submit_df.to_csv(test_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tn8iX4gqXIQi"
      },
      "id": "tn8iX4gqXIQi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88e68cb-dec1-439d-9363-03b817230bd1",
      "metadata": {
        "id": "c88e68cb-dec1-439d-9363-03b817230bd1"
      },
      "outputs": [],
      "source": [
        "for test_input_path, test_target_path in zip(test_input_list, test_target_list):\n",
        "    test_dataset = CustomDataset([test_input_path], [test_target_path], True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "    inference_per_case(best_model, test_loader, test_target_path, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###결과 파일을 zip 파일로 만들기"
      ],
      "metadata": {
        "id": "7Zv4NjQYAqs8"
      },
      "id": "7Zv4NjQYAqs8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173e281a-7a9f-4878-b406-4419698f7e0c",
      "metadata": {
        "id": "173e281a-7a9f-4878-b406-4419698f7e0c"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "os.chdir(\"./test_target/\")\n",
        "submission = zipfile.ZipFile(\"../submission.zip\", 'w')\n",
        "for path in test_target_list:\n",
        "    path = path.split('/')[-1]\n",
        "    submission.write(path)\n",
        "submission.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
